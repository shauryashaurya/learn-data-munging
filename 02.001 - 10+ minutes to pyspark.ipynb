{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a544b7b-bf71-4738-983a-56ed10e133eb",
   "metadata": {},
   "source": [
    "# Data Munging with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6427649f",
   "metadata": {},
   "source": [
    "### <font color='green'>_This notebook supports Google Colab_  </font>\n",
    "\n",
    "<font color='green'>Look for the \"_Sidebar_: Google Colab\" section below to setup and run this Spark notebook on Google Colab.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc95fc-c403-4556-8423-2ec83458f0db",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Installation etc.\n",
    "\n",
    "Look, I hate to be that guy, but Google/DDG are your friends here.  \n",
    "Getting ```Spark```, ```pySpark``` and other libraries to run is more than a little tedious.  \n",
    "The following are a 'best-guess' set of instrustions.  \n",
    "The ones that worked for me.  \n",
    "Using Windows 10 here.  \n",
    "Your mileage may vary.  \n",
    "\n",
    "Once you are through the tedium of installation and setup - it gets good. I promise. :)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec543e-8ec3-4d72-9b03-9f4c62725514",
   "metadata": {},
   "source": [
    "## Download (and install where applicable)\n",
    "* JDK (prefer 8.x/11.x, 64bit, more open the better)\n",
    "* Hadoop (3.2.x, at this time) - _for windows, we just need Hadoop Winutils_\n",
    "* [Hadoop *winutils* (corresponding to the version of Hadoop)](https://github.com/cdarlint/winutils), [another repo](https://github.com/kontext-tech/winutils)\n",
    "* [Spark (3.x, at this time)](https://spark.apache.org/downloads.html)  \n",
    "* [Anaconda - Open Source/Individual Edition](https://www.anaconda.com/products/distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b7fb1-d67d-4943-829f-7e21af47502f",
   "metadata": {},
   "source": [
    "## Setup environment variables \n",
    "\n",
    "We set these environment variables that help manage paths better.\n",
    "Example variable values would look like:\n",
    "Java:  \n",
    "* JAVA_HOME = ```C:\\[Java]```  \n",
    "    \n",
    "Hadoop:  \n",
    "* HADOOP_HOME = ```C:\\hadoop\\hadoop-3.4.0-win10-x64```  \n",
    "_this is just a sample_  \n",
    "_On Windows, we need HADOOP_HOME to be the folder where **winutils.exe** is located_  \n",
    "_For dev purposes: you can just download winutils and move on, just ensure you point to winutils.exe in this env variable_\n",
    "\n",
    "finally, Spark:   \n",
    "* SPARK_HOME = ```C:\\Spark\\spark-3.4.1-bin-hadoop3```  \n",
    "\n",
    "*notice there are no backslashes in the end. This is because slashes will be added in the next step when we setup path*      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba7dbaa-30d1-41ba-8573-3470d74abd0e",
   "metadata": {},
   "source": [
    "## Update system **'PATH'**\n",
    "\n",
    "We use the variables defined above to set-up paths.  \n",
    "\n",
    "* Java: ```%JAVA_HOME%/bin```\n",
    "* Hadoop 01: ```%HADOOP_HOME%/bin``` \n",
    "* Hadoop 02: ```%HADOOP_HOME%/sbin``` (*sbin needed in addition to bin*)\n",
    "* Spark: ```%SPARK_HOME%/bin```  \n",
    "    \n",
    "(*here we add backslashes before bin*)\n",
    "\n",
    "N.B.: If you are only doing the dev setup (just winutils and nothing else) thing, you may not need the Hadoop 01/02 above, I added those to my system anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7301fb83-c2ee-42a9-9c2c-57226377c48f",
   "metadata": {},
   "source": [
    "## Patch Hadoop  \n",
    "\n",
    "This is *needed* when Hadoop is run on Windows.\n",
    "\n",
    "* copy the ```bin``` folder from the right version of winutils to replace ```%HADOOP_HOME%/bin```  \n",
    "\n",
    "* copy ```hadoop-yarn-server-timelineservice-3.0.3``` from ```%HADOOP_HOME%\\share\\hadoop\\yarn\\timelineservice``` to ```%HADOOP_HOME%\\share\\hadoop\\yarn``` (the parent directory).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca5cdca-66e7-4cb2-aacd-11d8379630c9",
   "metadata": {},
   "source": [
    "## Install the Python libraries\n",
    "\n",
    "Prefer installing [Anaconda](https://www.anaconda.com/products/distribution). \n",
    "It resolves other dependencies like Pandas, Numpy, Jupyter etc. too.  \n",
    "Once there, use either pip or conda - they are both cool but incompatible.  \n",
    "The conda-forge channel is a few days behind the pip one.  \n",
    "We're only running on the local machine here, no complicated infrastructure to care about.  \n",
    "So, you do you.  \n",
    "\n",
    "Use one of the following commands (from the command line obvs) to install each:  \n",
    "* pyspark:\n",
    "    * ```pip install pyspark``` or\n",
    "    * ```conda install -c conda-forge pyspark```\n",
    "* findspark:\n",
    "    * ```pip install findspark``` or\n",
    "    * ```conda install -c conda-forge findspark```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e98fc72-dbd6-49db-afc9-9c16e10385d3",
   "metadata": {},
   "source": [
    "## References  \n",
    "\n",
    "* [How to install Hadoop on Win 10](https://muhammadbilalyar.github.io/blogs/How-to-install-Hadoop-on-Window-10/)\n",
    "* [Hadoop on Windows](https://github.com/MuhammadBilalYar/Hadoop-On-Window)\n",
    "* [Hadoop and Spark on Windows](https://dev.to/awwsmm/installing-and-running-hadoop-and-spark-on-windows-33kc)\n",
    "\n",
    "### (_Optionally_) Configure Hadoop\n",
    "\n",
    "*only needed if you want to use hadoop as your file storage system*  \n",
    "\n",
    "* create a folder for ```namenode```\n",
    "* create a folder for ```datanode```\n",
    "* four files: ```core-site.xml```, ```mapred-site.xml```, ```hdfs-site.xml```, ```yarn-site.xml``` - see code for each in the [reference repo](https://github.com/MuhammadBilalYar/Hadoop-On-Window) above.\n",
    "\n",
    "### Also,\n",
    "\n",
    "The scope of this notebook is *usage* - not setup or troubleshooting, am pretty sure these installation instructions will be outdated soon and be replaced by pre-built docker images or shell scripts or automated installs for windows or such-like.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445cf8df-816d-4e9f-937d-f711263a2189",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "This boiler plate helps, esp. in Jupyter Notebook situations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa61211d",
   "metadata": {},
   "source": [
    "## _Sidebar_: Google Colab\n",
    "\n",
    "You don't need to run this on your local machine.\n",
    "The notebook is setup to run on Google Colab as well.\n",
    "\n",
    "For a detailed description of how this is setup, see the [02.000 (optional) Setup_Spark_in_Google_Colab](https://github.com/shauryashaurya/learn-data-munging/blob/main/02.000%20(optional)%20Setup_Spark_in_Google_Colab.ipynb) notebook\n",
    "\n",
    "Open the notebook in Google Colab using the following button, then uncomment the setup marked # SETUP FOR COLAB  \n",
    "  \n",
    "  \n",
    "<a href=\"https://colab.research.google.com/github/shauryashaurya/learn-data-munging/blob/main/02.001%20-%2010%2B%20minutes%20to%20pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>    \n",
    "\n",
    "_NOTE: keep the # SETUP FOR COLAB step below commented (disabled) when you are running this notebook locally_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b538d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP FOR COLAB: select all the lines below and uncomment (CTRL+/ on windows)\n",
    "\n",
    "# # grab spark\n",
    "# # as of Dec 2022, the latest version is 3.2.3, get the link from Apache Spark's website\n",
    "# ! wget -q https://dlcdn.apache.org/spark/spark-3.2.3/spark-3.2.3-bin-hadoop3.2.tgz\n",
    "# # unzip spark\n",
    "# !tar xf spark-3.2.3-bin-hadoop3.2.tgz\n",
    "# # install findspark package\n",
    "# !pip install -q findspark\n",
    "\n",
    "# # got to provide JAVA_HOME and SPARK_HOME vairables\n",
    "# import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.3-bin-hadoop3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d7fca2-50cb-44d7-ae1e-e35ac201a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: initialize findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffcf28b-084b-4227-8bb3-d7a714c9e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: import pyspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aec09686-86ce-46a6-bc8f-ad2801530277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa73c1c-b624-478a-ab4c-2b43dc896a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a spark session\n",
    "\n",
    "# 'local[1]' indicates spark on 1 core on the local machine, specify the number of cores needed\n",
    "# use .config(\"spark.some.config.option\", \"some-value\") for additional configuration\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[1]') \\\n",
    "    .appName(\"10+ minutes to pyspark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4196ac0a-608f-4632-a456-d30b1ed57efc",
   "metadata": {},
   "source": [
    "Back in the day you'd need various 'contexts' as entry points into spark functionality.  \n",
    "All of this is now wrapped into a SparkSession, easy to manage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769ab4a-2aec-4324-9aec-c678e6f7929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SparkSession carries the sparkContext\n",
    "# spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b128f6-7001-4f98-8204-2e6ff76c4366",
   "metadata": {},
   "source": [
    "Check out the spark UI link when you uncomment the lines in the two cells above.  \n",
    "Your local UI should launch at a link like: http://localhost:4041/jobs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae8fd9ee-5023-46ed-8c2c-202ba45e138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we close the notebook, stop spark, otherwise Jupyter closes, but scala-spark keep going on...\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9596fcf-6641-4ccc-94fd-0cac6b4f28bf",
   "metadata": {},
   "source": [
    "# Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ce9eb-a318-4782-b83b-a3e1d1b03ad4",
   "metadata": {},
   "source": [
    "## DataFrames: Create and View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f8ace1-e5fe-473d-880f-dc41d2c2888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a0c32e-9b00-42be-98b3-58759ab43864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a list of pyspark.sql.Row\n",
    "df1 = spark.createDataFrame(\n",
    "    [\n",
    "        Row(a=1,b=2.,c='span a',d=date(2022,7,1),e=datetime(2022,7,1,12,0)),\n",
    "        Row(a=1,b=3.,c='can a ',d=date(2022,7,2),e=datetime(2022,7,2,12,0,1)),\n",
    "        Row(a=1,b=4.,c='banana',d=date(2022,7,3),e=datetime(2022,7,3,12,0,2))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51454297-dd70-4126-8502-ff56068ff68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3b8125b-16ca-49b9-9625-d2223b0faabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+----------+-------------------+\n",
      "|  a|  b|     c|         d|                  e|\n",
      "+---+---+------+----------+-------------------+\n",
      "|  1|2.0|span a|2022-07-01|2022-07-01 12:00:00|\n",
      "|  1|3.0|can a |2022-07-02|2022-07-02 12:00:01|\n",
      "|  1|4.0|banana|2022-07-03|2022-07-03 12:00:02|\n",
      "+---+---+------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df1's not been evaluated yet. It's lazy evaluation\n",
    "# to eval it, we go\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "019bdf5d-6461-41a7-a207-68ebf1e409e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a list of tuples with explicit schema\n",
    "df2 = spark.createDataFrame(\n",
    "    [\n",
    "        (2,5.,'man a',date(2022,7,1),datetime(2022,7,1,12,0)),\n",
    "        (2,6.,'can a',date(2022,8,1),datetime(2022,7,2,12,0)),\n",
    "        (2,7.,'manna',date(2022,9,1),datetime(2022,7,3,12,0))\n",
    "    ],\n",
    "    schema = 'a bigint, b double, c string, d date, e timestamp'\n",
    ")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2ba1bfe-4867-4ad1-8e33-acfa6b312b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use spark RDDs to create a dataframe\n",
    "# go to the sparksession's sparkContext to access parallelize method\n",
    "rdd3 = spark.sparkContext.parallelize(\n",
    "    [\n",
    "        (3,5., 'main', date(2022,7,1), datetime(2022,7,1,12,0,1)),\n",
    "        (3,5., 'brain', date(2022,7,1), datetime(2022,7,1,12,0,1)),\n",
    "        (3,5., 'pain', date(2022,7,1), datetime(2022,7,1,12,0,1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "df3 = spark.createDataFrame(rdd3, schema=['a','b','c','d','e'])\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66e30524-a08e-4f72-ad29-6a61b1fe3236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  a|                 b|                c|         d|                  e|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  0|1.3461612779974976|gandalf's manager|2022-07-01|2022-07-01 12:00:01|\n",
      "|  3|0.8235447997632228|             said|2022-07-02|2022-07-02 12:00:02|\n",
      "|  3|1.1436223517625508|               no|2022-07-03|2022-07-03 12:00:03|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# can also use a pandas dataframe to create a spark dataframe\n",
    "df4_pd = pd.DataFrame(\n",
    "    {\n",
    "        'a': np.random.randint(0,10, size = 3),\n",
    "        'b': np.random.randn(3),\n",
    "        'c': [\"gandalf's manager\", \"said\", 'no'],\n",
    "        'd': [date(2022,7,1),date(2022,7,2),date(2022,7,3)],\n",
    "        'e': [datetime(2022,7,1,12,0,1),datetime(2022,7,2,12,0,2),datetime(2022,7,3,12,0,3)]\n",
    "    }\n",
    ")\n",
    "\n",
    "df4 = spark.createDataFrame(df4_pd)\n",
    "\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29122a68-ee0c-4d07-b6d3-c6900a5cd713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.346161</td>\n",
       "      <td>gandalf's manager</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-01 12:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.823545</td>\n",
       "      <td>said</td>\n",
       "      <td>2022-07-02</td>\n",
       "      <td>2022-07-02 12:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.143622</td>\n",
       "      <td>no</td>\n",
       "      <td>2022-07-03</td>\n",
       "      <td>2022-07-03 12:00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a         b                  c           d                   e\n",
       "0  0  1.346161  gandalf's manager  2022-07-01 2022-07-01 12:00:01\n",
       "1  3  0.823545               said  2022-07-02 2022-07-02 12:00:02\n",
       "2  3  1.143622                 no  2022-07-03 2022-07-03 12:00:03"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d6bdf10-9527-4cad-8e71-1e2b4529c040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use printSchema() to..., you know, it says what it does\n",
    "# also don't you hate that pySpark is following the Java camelCase instead of the Python snake_case?\n",
    "# yeah, what's that all about?\n",
    "\n",
    "df1.printSchema()\n",
    "df2.printSchema()\n",
    "df3.printSchema()\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33356611-4248-4825-8cff-69377bba13cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+----------+-------------------+\n",
      "|  a|  b|     c|         d|                  e|\n",
      "+---+---+------+----------+-------------------+\n",
      "|  1|2.0|span a|2022-07-01|2022-07-01 12:00:00|\n",
      "+---+---+------+----------+-------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "-RECORD 0------------------\n",
      " a   | 0                   \n",
      " b   | 1.3461612779974976  \n",
      " c   | gandalf's manager   \n",
      " d   | 2022-07-01          \n",
      " e   | 2022-07-01 12:00:01 \n",
      "-RECORD 1------------------\n",
      " a   | 3                   \n",
      " b   | 0.8235447997632228  \n",
      " c   | said                \n",
      " d   | 2022-07-02          \n",
      " e   | 2022-07-02 12:00:02 \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show only x rows\n",
    "df1.show(1)\n",
    "# vertical - if the row is too long for horizontal display\n",
    "df4.show(2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecf225d7-710e-4e69-80f7-f63bd7a89147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=3, b=5.0, c='main', d=datetime.date(2022, 7, 1), e=datetime.datetime(2022, 7, 1, 12, 0, 1)),\n",
       " Row(a=3, b=5.0, c='brain', d=datetime.date(2022, 7, 1), e=datetime.datetime(2022, 7, 1, 12, 0, 1)),\n",
       " Row(a=3, b=5.0, c='pain', d=datetime.date(2022, 7, 1), e=datetime.datetime(2022, 7, 1, 12, 0, 1))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect() - collects the entire df from across all nodes to the driver\n",
    "# if you don't have enough memory, here's how you crash spark\n",
    "# careful is the word\n",
    "df3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d415b40-f85f-4a95-89de-189aa16e617f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=2, b=5.0, c='man a', d=datetime.date(2022, 7, 1), e=datetime.datetime(2022, 7, 1, 12, 0)),\n",
       " Row(a=2, b=6.0, c='can a', d=datetime.date(2022, 8, 1), e=datetime.datetime(2022, 7, 2, 12, 0))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas used to have a take() method, deprecated now\n",
    "# take() in spark extracts the first n rows of a dataframe\n",
    "df2.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f0d793a-a269-46c4-82ba-c3a9c5f4a89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=2, b=6.0, c='can a', d=datetime.date(2022, 8, 1), e=datetime.datetime(2022, 7, 2, 12, 0)),\n",
       " Row(a=2, b=7.0, c='manna', d=datetime.date(2022, 9, 1), e=datetime.datetime(2022, 7, 3, 12, 0))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as take() but returns the last n rows of a dataframe\n",
    "df2.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df8be5f3-ca9e-4103-8ec4-bc7a9acc3099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>main</td>\n",
       "      <td>2022-07-01 00:00:00</td>\n",
       "      <td>2022-07-01 12:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>brain</td>\n",
       "      <td>2022-07-01 00:00:00</td>\n",
       "      <td>2022-07-01 12:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pain</td>\n",
       "      <td>2022-07-01 00:00:00</td>\n",
       "      <td>2022-07-01 12:00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a    b      c                    d                    e\n",
       "0  3  5.0   main  2022-07-01 00:00:00  2022-07-01 12:00:01\n",
       "1  3  5.0  brain  2022-07-01 00:00:00  2022-07-01 12:00:01\n",
       "2  3  5.0   pain  2022-07-01 00:00:00  2022-07-01 12:00:01"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hey you want another way of crashing the spark driver?\n",
    "# convert the spark dataframe to a pandas dataframe\n",
    "# it'll collect all data from all workers into the driver\n",
    "\n",
    "# this naive approach will fail because we have date-time values in df3 . \n",
    "# df3.toPandas()\n",
    "# possible error: TypeError: Casting to unit-less dtype 'datetime64' is not supported. Pass e.g. 'datetime64[ns]' instead.\n",
    "\n",
    "# explicitly provide date-time data type to Pandas\n",
    "from pyspark.sql.functions import date_format\n",
    "df3.withColumn(\"d\", date_format(\"d\", \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "    .withColumn(\"e\", date_format(\"e\", \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f49288e-7455-4a84-b2bd-237ad913d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do I make it so my dataframes are evaluated eagerly?\n",
    "# instead of the regular lazy eval?\n",
    "# y'know when am in notebooks and stuff?\n",
    "# set the config\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b60f9473-8440-417f-909b-dd7b6060fc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>a</th><th>b</th><th>c</th><th>d</th><th>e</th></tr>\n",
       "<tr><td>1</td><td>2.0</td><td>span a</td><td>2022-07-01</td><td>2022-07-01 12:00:00</td></tr>\n",
       "<tr><td>1</td><td>3.0</td><td>can a </td><td>2022-07-02</td><td>2022-07-02 12:00:01</td></tr>\n",
       "<tr><td>1</td><td>4.0</td><td>banana</td><td>2022-07-03</td><td>2022-07-03 12:00:02</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there you go, eager evaulatio'\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d446b176-8186-4aa7-bd72-e6e481b130fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set it back to false if you like\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2725b11-35f6-488a-95a1-eef0b27cec73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No more eagerly evaluated dataframes\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d15109-8688-4106-bb8f-e631b9b9f58a",
   "metadata": {},
   "source": [
    "# Selecting and Accessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37b63bf6-0858-44c2-b5f6-f76fec5dc681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Column<'a'>, Column<'b'>, Column<'c'>, Column<'d'>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access a column\n",
    "df1.a, df2.b, df3.c, df4.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d307d39a-b253-42fc-9891-1874efbff6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Column\n",
    "from pyspark.sql.functions import upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "893f2913-e512-40c1-b2db-592bbe923e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df1.c) == type(upper(df1.c)) == type(df1.c.isNull())\n",
    "# TODO: what's going on with type(df1.c.isNull()) above???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ea79385-3d12-4fd3-9b91-a69c0d068e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(c IS NULL)'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.c.isNull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7aefb474-fc0d-4d9c-b702-84c4e9baa02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|     c|\n",
      "+------+\n",
      "|span a|\n",
      "|can a |\n",
      "|banana|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use dataframe's select method to identify a column and show() it\n",
    "df1.select(df1.c).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fe31305-cf4b-4956-8fe2-52381e13fa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+----+----------+-------------------+\n",
      "|  a|                 b|   c|         d|                  e|\n",
      "+---+------------------+----+----------+-------------------+\n",
      "|  3|0.8235447997632228|said|2022-07-02|2022-07-02 12:00:02|\n",
      "|  3|1.1436223517625508|  no|2022-07-03|2022-07-03 12:00:03|\n",
      "+---+------------------+----+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# also there's dataframe.filter()\n",
    "df4.filter(df4.a>0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "989931c3-1191-4706-93e4-21f299b3ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7c17a5d-ae8a-4c45-998f-0685497d5202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+----------+-------------------+-----------------+\n",
      "|  a|                 b|                c|         d|                  e|          upper_c|\n",
      "+---+------------------+-----------------+----------+-------------------+-----------------+\n",
      "|  0|1.3461612779974976|gandalf's manager|2022-07-01|2022-07-01 12:00:01|GANDALF'S MANAGER|\n",
      "|  3|0.8235447997632228|             said|2022-07-02|2022-07-02 12:00:02|             SAID|\n",
      "|  3|1.1436223517625508|               no|2022-07-03|2022-07-03 12:00:03|               NO|\n",
      "+---+------------------+-----------------+----------+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assign a new column instance to the dataframe\n",
    "df4_withNewCol = df4.withColumn('upper_c', upper(df4.c))\n",
    "df4_withNewCol.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "770ee356-4dad-47a9-9cfb-900231fec55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  a|                 b|                c|         d|                  e|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  0|1.3461612779974976|gandalf's manager|2022-07-01|2022-07-01 12:00:01|\n",
      "|  3|0.8235447997632228|             said|2022-07-02|2022-07-02 12:00:02|\n",
      "|  3|1.1436223517625508|               no|2022-07-03|2022-07-03 12:00:03|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "\n",
      "+---+------------------+-----------------+----------+-------------------+-----------------+\n",
      "|  a|                 b|                c|         d|                  e|          upper_c|\n",
      "+---+------------------+-----------------+----------+-------------------+-----------------+\n",
      "|  0|1.3461612779974976|gandalf's manager|2022-07-01|2022-07-01 12:00:01|GANDALF'S MANAGER|\n",
      "|  3|0.8235447997632228|             said|2022-07-02|2022-07-02 12:00:02|             SAID|\n",
      "|  3|1.1436223517625508|               no|2022-07-03|2022-07-03 12:00:03|               NO|\n",
      "+---+------------------+-----------------+----------+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show()\n",
    "df4_withNewCol.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2b7c395-3668-46e5-89ae-ab801c5009ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+\n",
      "|  a|  b|  c|  d|  e|\n",
      "+---+---+---+---+---+\n",
      "+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "df4.filter(df4.a == 9).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37002785-5d6f-4d06-aa0e-dfa309dc24c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  a|                 b|                c|         d|                  e|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  0|1.3461612779974976|gandalf's manager|2022-07-01|2022-07-01 12:00:01|\n",
      "|  3|0.8235447997632228|             said|2022-07-02|2022-07-02 12:00:02|\n",
      "|  3|1.1436223517625508|               no|2022-07-03|2022-07-03 12:00:03|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.filter(df4.b > 0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b895559-ebb0-49df-849e-2bc5d5b1839d",
   "metadata": {},
   "source": [
    "# UDFs: Applying a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8705daf5-a919-4097-9280-a90630ec6871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|  a|pandas_plus_one(a)|\n",
      "+---+------------------+\n",
      "|  0|                 1|\n",
      "|  3|                 4|\n",
      "|  3|                 4|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "\n",
    "@pandas_udf('long')\n",
    "def pandas_plus_one(series: pd.Series) -> pd.Series:\n",
    "    #     plus one using pandas series\n",
    "    return series+1\n",
    "\n",
    "df4.select(df4.a, pandas_plus_one(df4.a)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0d946c1-48cd-4693-a360-96bfb29ec43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  a|                 b|                c|         d|                  e|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  0|1.3461612779974976|gandalf's manager|2022-07-01|2022-07-01 12:00:01|\n",
      "|  3|0.8235447997632228|             said|2022-07-02|2022-07-02 12:00:02|\n",
      "|  3|1.1436223517625508|               no|2022-07-03|2022-07-03 12:00:03|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def pandas_filter(iterator):\n",
    "    for pandas_df in iterator:\n",
    "        yield pandas_df[pandas_df.b>0]\n",
    "        \n",
    "df4.mapInPandas(pandas_filter, schema = df4.schema).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d967daa8-65ea-4704-a097-32f22619c993",
   "metadata": {},
   "source": [
    "# Grouping Data\n",
    "\n",
    "Split-Apply-Combine, just like pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d2ba63a-e9db-477d-af55-bd6ffd955ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+---+\n",
      "|color| fruit| v1| v2|\n",
      "+-----+------+---+---+\n",
      "|  red|banana|  1| 10|\n",
      "| blue|banana|  2| 20|\n",
      "|  red|carrot|  3| 30|\n",
      "| blue| grape|  4| 40|\n",
      "|  red|carrot|  5| 50|\n",
      "|black|carrot|  6| 60|\n",
      "|  red|banana|  7| 70|\n",
      "|  red| grape|  8| 80|\n",
      "+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group by fruit, color etc.\n",
    "df5 = spark.createDataFrame([\n",
    "    ['red', 'banana', 1, 10], ['blue', 'banana', 2, 20], ['red', 'carrot', 3, 30],\n",
    "    ['blue', 'grape', 4, 40], ['red', 'carrot', 5, 50], ['black', 'carrot', 6, 60],\n",
    "    ['red', 'banana', 7, 70], ['red', 'grape', 8, 80]], schema=['color', 'fruit', 'v1', 'v2'])\n",
    "\n",
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb849da3-352d-4ab6-aed7-bbd79307f4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+\n",
      "|color|avg(v1)|avg(v2)|\n",
      "+-----+-------+-------+\n",
      "|  red|    4.8|   48.0|\n",
      "|black|    6.0|   60.0|\n",
      "| blue|    3.0|   30.0|\n",
      "+-----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.groupby('color').avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a36dd4ae-b463-45ff-a328-63c53a67748c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+---+\n",
      "|color| fruit| v1| v2|\n",
      "+-----+------+---+---+\n",
      "|black|carrot|  0| 60|\n",
      "| blue|banana| -1| 20|\n",
      "| blue| grape|  1| 40|\n",
      "|  red|banana| -3| 10|\n",
      "|  red|carrot| -1| 30|\n",
      "|  red|carrot|  0| 50|\n",
      "|  red|banana|  2| 70|\n",
      "|  red| grape|  3| 80|\n",
      "+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: How to get the deviations in a new column?\n",
    "def plus_mean(pandas_df):\n",
    "    return pandas_df.assign(v1=pandas_df.v1 - pandas_df.v1.mean())\n",
    "\n",
    "df5.groupby('color').applyInPandas(plus_mean, schema = df5.schema).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "556e1244-6157-4f61-b7c9-fabb8a423db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-grouping and applying a function.\n",
    "\n",
    "df6 = spark.createDataFrame(\n",
    "    [\n",
    "        (20000101, 1, 1.0), \n",
    "        (20000101, 2, 2.0), \n",
    "        (20000102, 1, 3.0), \n",
    "        (20000102, 2, 4.0)\n",
    "    ],\n",
    "    ('time', 'id', 'v1')\n",
    ")\n",
    "\n",
    "df7 = spark.createDataFrame(\n",
    "    [\n",
    "        (20000101, 1, 'x'), \n",
    "        (20000101, 2, 'y')\n",
    "    ],\n",
    "    ('time', 'id', 'v2')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "424c472e-0e6e-45c0-83c4-be4a128fe8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asof_join(l, r):\n",
    "    return pd.merge_asof(l,r,on='time', by='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36b10405-0406-4526-be30-a4df2b2cd6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6_gb = df6.groupby('id')\n",
    "df7_gb = df7.groupby('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da0171df-3121-4a56-b78d-f20ef56fcae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_grp = df6_gb.cogroup(df7_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eae2ec3d-0699-4536-b048-a2f61be71fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---+---+\n",
      "|    time| id| v1| v2|\n",
      "+--------+---+---+---+\n",
      "|20000101|  1|1.0|  x|\n",
      "|20000102|  1|3.0|  x|\n",
      "|20000101|  2|2.0|  y|\n",
      "|20000102|  2|4.0|  y|\n",
      "+--------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rslt = co_grp.applyInPandas(asof_join, schema='time int, id int, v1 double, v2 string')\n",
    "rslt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9eb347-0c6b-4c7a-b95e-03f8e930e220",
   "metadata": {},
   "source": [
    "# Getting data in and out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "746de44d-7c20-456d-bee9-ad657f12b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+---+\n",
      "|color| fruit| v1| v2|\n",
      "+-----+------+---+---+\n",
      "|  red|banana|  1| 10|\n",
      "| blue|banana|  2| 20|\n",
      "|  red|carrot|  3| 30|\n",
      "| blue| grape|  4| 40|\n",
      "|  red|carrot|  5| 50|\n",
      "|black|carrot|  6| 60|\n",
      "|  red|banana|  7| 70|\n",
      "|  red| grape|  8| 80|\n",
      "+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CSV\n",
    "# .mode('overwrite') can be taken out when needed.\n",
    "df5.write.mode('overwrite').csv('fruits.csv', header=True)\n",
    "spark.read.csv('fruits.csv', header=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2869caf-bb97-4d65-a439-abcd54b387b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+---+\n",
      "|color| fruit| v1| v2|\n",
      "+-----+------+---+---+\n",
      "|  red|banana|  1| 10|\n",
      "| blue|banana|  2| 20|\n",
      "|  red|carrot|  3| 30|\n",
      "| blue| grape|  4| 40|\n",
      "|  red|carrot|  5| 50|\n",
      "|black|carrot|  6| 60|\n",
      "|  red|banana|  7| 70|\n",
      "|  red| grape|  8| 80|\n",
      "+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parquet\n",
    "# .mode('overwrite') can be taken out when needed.\n",
    "df5.write.mode('overwrite').parquet('fruits.parquet')\n",
    "spark.read.parquet('fruits.parquet').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0bf0e5-675b-47de-aaff-30b8dda710ba",
   "metadata": {},
   "source": [
    "# Working with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2f76a79-4196-40a0-8911-2b16b90fb3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.createOrReplaceTempView('tableA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71cf4ac5-9523-4837-bc7c-276ccd963317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       8|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(*) from tableA').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10234261-9c90-47cb-8f8f-bc6410cb67f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.add_one(s: pandas.core.series.Series) -> pandas.core.series.Series>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UDFs in SQL\n",
    "# register and invoke\n",
    "@pandas_udf('integer')\n",
    "def add_one(s: pd.Series) -> pd.Series:\n",
    "    return s+1\n",
    "\n",
    "spark.udf.register('add_one', add_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33d62221-e6d4-43dc-8864-455f64824782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "| v1|add_one(v1)|\n",
      "+---+-----------+\n",
      "|  1|          2|\n",
      "|  2|          3|\n",
      "|  3|          4|\n",
      "|  4|          5|\n",
      "|  5|          6|\n",
      "|  6|          7|\n",
      "|  7|          8|\n",
      "|  8|          9|\n",
      "+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT v1, add_one(v1) from tableA').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e6c181f2-978c-44af-a436-08e6098b01ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|add_one(v1)|\n",
      "+-----------+\n",
      "|          2|\n",
      "|          3|\n",
      "|          4|\n",
      "|          5|\n",
      "|          6|\n",
      "|          7|\n",
      "|          8|\n",
      "|          9|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# can mix/match sql expressions \n",
    "# for e.g. take the expressions from above\n",
    "\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df5.selectExpr('add_one(v1)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55466bb4-3b91-4d75-9848-937ec8020bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       8|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.select(expr('count(*)')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75739657-6e2e-4a58-b33d-43e0f3588cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|(count(1) > 0)|\n",
      "+--------------+\n",
      "|          true|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.select(expr('count(*)')>0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77513663-399f-400a-8be1-c66945461b82",
   "metadata": {},
   "source": [
    "# Pandas API on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26873600-5e9e-4d32-813b-50a136f9256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\1\\spark-3.4.1-bin-hadoop3\\python\\pyspark\\pandas\\__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8097116d-aaea-404c-9911-0187a766bc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    3.0\n",
       "3    NaN\n",
       "4    5.0\n",
       "5    NaN\n",
       "6    7.0\n",
       "7    8.0\n",
       "8    9.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pandas on spark series\n",
    "\n",
    "s1 = ps.Series([1,2,3,np.nan,5,np.nan,7,8,9])\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7d4d032e-2d95-44ac-8df1-fe22957896af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>six</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a    b      c\n",
       "10  1  100    one\n",
       "20  2  200    two\n",
       "30  3  300  three\n",
       "40  4  400   four\n",
       "50  5  500   five\n",
       "60  6  600    six"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf1 = ps.DataFrame(\n",
    "    {'a': [1, 2, 3, 4, 5, 6],\n",
    "     'b': [100, 200, 300, 400, 500, 600],\n",
    "     'c': [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\"]\n",
    "    },\n",
    "    index=[10, 20, 30, 40, 50, 60]\n",
    ")\n",
    "\n",
    "psdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a8fdb212-22f8-41f3-b328-71784cb501f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas dataframe and convert to pandas-spark\n",
    "dates1 = pd.date_range('20220101', periods=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "40d83068-727d-46d3-a332-c7edf553abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf1 = pd.DataFrame(np.random.randn(6,4), index=dates1, columns = list('ABCD'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a2b1bd54-ff57-4631-bcf5-6fd0626ace80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>-0.168990</td>\n",
       "      <td>0.218452</td>\n",
       "      <td>-0.213017</td>\n",
       "      <td>-1.393176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>0.708587</td>\n",
       "      <td>-0.443116</td>\n",
       "      <td>-0.450608</td>\n",
       "      <td>-1.138874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>0.134243</td>\n",
       "      <td>-0.210103</td>\n",
       "      <td>0.617508</td>\n",
       "      <td>-1.238837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>-1.952191</td>\n",
       "      <td>1.187688</td>\n",
       "      <td>0.344275</td>\n",
       "      <td>-0.500572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>-0.313474</td>\n",
       "      <td>-0.050070</td>\n",
       "      <td>1.588762</td>\n",
       "      <td>-0.064186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>0.268115</td>\n",
       "      <td>0.743052</td>\n",
       "      <td>0.202203</td>\n",
       "      <td>-0.840306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2022-01-01 -0.168990  0.218452 -0.213017 -1.393176\n",
       "2022-01-02  0.708587 -0.443116 -0.450608 -1.138874\n",
       "2022-01-03  0.134243 -0.210103  0.617508 -1.238837\n",
       "2022-01-04 -1.952191  1.187688  0.344275 -0.500572\n",
       "2022-01-05 -0.313474 -0.050070  1.588762 -0.064186\n",
       "2022-01-06  0.268115  0.743052  0.202203 -0.840306"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3940049a-133a-49ab-bd5f-4dc4ae399a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04',\n",
       "               '2022-01-05', '2022-01-06'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a43a24d8-77ac-4423-86c4-c274036e1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark dataframe from the pandas dataframe\n",
    "\n",
    "# naive method breaks with pandas 2.x due to date-time column\n",
    "# psdf1 = ps.from_pandas(pdf1)\n",
    "\n",
    "# we follow a 2-step approach here:\n",
    "# first convert datetime to string\n",
    "pdf1.index = pdf1.index.astype(\"string\")\n",
    "psdf1 = ps.from_pandas(pdf1)\n",
    "\n",
    "# now cast index back to datetime64 \n",
    "psdf1.index = psdf1.index.astype(\"datetime64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5f5c202f-86a7-497c-b3ea-6d7101cef227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.pandas.frame.DataFrame"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a pandas-on-spark dataframe now\n",
    "type(psdf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b966d8b7-1be4-4117-89e8-24eee3bbd569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>0.231783</td>\n",
       "      <td>-1.084731</td>\n",
       "      <td>-0.608712</td>\n",
       "      <td>1.246273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>-0.805125</td>\n",
       "      <td>-2.042498</td>\n",
       "      <td>-0.830551</td>\n",
       "      <td>0.660595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>-1.364529</td>\n",
       "      <td>-1.882992</td>\n",
       "      <td>1.696941</td>\n",
       "      <td>0.615413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>0.873966</td>\n",
       "      <td>1.508365</td>\n",
       "      <td>-1.282595</td>\n",
       "      <td>0.707897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>-0.253708</td>\n",
       "      <td>0.637862</td>\n",
       "      <td>-0.188042</td>\n",
       "      <td>-0.059372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>0.166734</td>\n",
       "      <td>0.417695</td>\n",
       "      <td>-1.107310</td>\n",
       "      <td>-0.194818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2022-01-01  0.231783 -1.084731 -0.608712  1.246273\n",
       "2022-01-02 -0.805125 -2.042498 -0.830551  0.660595\n",
       "2022-01-03 -1.364529 -1.882992  1.696941  0.615413\n",
       "2022-01-04  0.873966  1.508365 -1.282595  0.707897\n",
       "2022-01-05 -0.253708  0.637862 -0.188042 -0.059372\n",
       "2022-01-06  0.166734  0.417695 -1.107310 -0.194818"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "608b5c19-d254-47b1-8db9-3469a0d7c5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+--------------------+\n",
      "|                   A|                  B|                  C|                   D|\n",
      "+--------------------+-------------------+-------------------+--------------------+\n",
      "| 0.23178298083436075|-1.0847310277456157|-0.6087115856498937|  1.2462731288493991|\n",
      "| -0.8051253969964965|-2.0424981029532785|-0.8305510126251235|  0.6605951086327256|\n",
      "| -1.3645288946045742| -1.882992437515232| 1.6969414646290797|  0.6154125218090376|\n",
      "|  0.8739660400170647| 1.5083646652561309|-1.2825951299127099|    0.70789746162282|\n",
      "|-0.25370835805637826| 0.6378616352178663|-0.1880421255151992| -0.0593716881962378|\n",
      "| 0.16673376667661077|0.41769524872208375|-1.1073103769831572|-0.19481750928898367|\n",
      "+--------------------+-------------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a SPARK df from a PANDAS df (we've done this before)\n",
    "# create a PANDAS-ON-SPARK df from a SPARK df (we've done this too...)\n",
    "\n",
    "sdf2 = spark.createDataFrame(pdf1)\n",
    "sdf2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4124fe81-2591-4177-bfb1-4ccdbd0dd217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.231783</td>\n",
       "      <td>-1.084731</td>\n",
       "      <td>-0.608712</td>\n",
       "      <td>1.246273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.805125</td>\n",
       "      <td>-2.042498</td>\n",
       "      <td>-0.830551</td>\n",
       "      <td>0.660595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.364529</td>\n",
       "      <td>-1.882992</td>\n",
       "      <td>1.696941</td>\n",
       "      <td>0.615413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.873966</td>\n",
       "      <td>1.508365</td>\n",
       "      <td>-1.282595</td>\n",
       "      <td>0.707897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.253708</td>\n",
       "      <td>0.637862</td>\n",
       "      <td>-0.188042</td>\n",
       "      <td>-0.059372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.166734</td>\n",
       "      <td>0.417695</td>\n",
       "      <td>-1.107310</td>\n",
       "      <td>-0.194818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0  0.231783 -1.084731 -0.608712  1.246273\n",
       "1 -0.805125 -2.042498 -0.830551  0.660595\n",
       "2 -1.364529 -1.882992  1.696941  0.615413\n",
       "3  0.873966  1.508365 -1.282595  0.707897\n",
       "4 -0.253708  0.637862 -0.188042 -0.059372\n",
       "5  0.166734  0.417695 -1.107310 -0.194818"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf2 = sdf2.pandas_api()\n",
    "# this works like a pandas df now...\n",
    "psdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9afc3f8e-b8a4-4aa4-9f56-e0c6d0a3f55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.pandas.frame.DataFrame"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(psdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7b9b4b6c-103c-4c90-95c1-5ff34214bcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    float64\n",
       "B    float64\n",
       "C    float64\n",
       "D    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f1303255-1f39-42e8-8d76-c9ba054dff9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.231783</td>\n",
       "      <td>-1.084731</td>\n",
       "      <td>-0.608712</td>\n",
       "      <td>1.246273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.805125</td>\n",
       "      <td>-2.042498</td>\n",
       "      <td>-0.830551</td>\n",
       "      <td>0.660595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.364529</td>\n",
       "      <td>-1.882992</td>\n",
       "      <td>1.696941</td>\n",
       "      <td>0.615413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.873966</td>\n",
       "      <td>1.508365</td>\n",
       "      <td>-1.282595</td>\n",
       "      <td>0.707897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.253708</td>\n",
       "      <td>0.637862</td>\n",
       "      <td>-0.188042</td>\n",
       "      <td>-0.059372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0  0.231783 -1.084731 -0.608712  1.246273\n",
       "1 -0.805125 -2.042498 -0.830551  0.660595\n",
       "2 -1.364529 -1.882992  1.696941  0.615413\n",
       "3  0.873966  1.508365 -1.282595  0.707897\n",
       "4 -0.253708  0.637862 -0.188042 -0.059372"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas head()\n",
    "psdf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e3f80c80-1f13-450c-8c5d-0f7f3ac3d181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2, 3, 4, 5], dtype='int64')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "836234ff-538c-44e1-ac85-ec0eb74c26dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'B', 'C', 'D'], dtype='object')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "be81bd98-1c33-4916-9457-f269ec38f28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.191813</td>\n",
       "      <td>-0.407717</td>\n",
       "      <td>-0.386711</td>\n",
       "      <td>0.495998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.799890</td>\n",
       "      <td>1.466506</td>\n",
       "      <td>1.090800</td>\n",
       "      <td>0.535692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.364529</td>\n",
       "      <td>-2.042498</td>\n",
       "      <td>-1.282595</td>\n",
       "      <td>-0.194818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.805125</td>\n",
       "      <td>-1.882992</td>\n",
       "      <td>-1.107310</td>\n",
       "      <td>-0.059372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.253708</td>\n",
       "      <td>-1.084731</td>\n",
       "      <td>-0.830551</td>\n",
       "      <td>0.615413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.231783</td>\n",
       "      <td>0.637862</td>\n",
       "      <td>-0.188042</td>\n",
       "      <td>0.707897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.873966</td>\n",
       "      <td>1.508365</td>\n",
       "      <td>1.696941</td>\n",
       "      <td>1.246273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B         C         D\n",
       "count  6.000000  6.000000  6.000000  6.000000\n",
       "mean  -0.191813 -0.407717 -0.386711  0.495998\n",
       "std    0.799890  1.466506  1.090800  0.535692\n",
       "min   -1.364529 -2.042498 -1.282595 -0.194818\n",
       "25%   -0.805125 -1.882992 -1.107310 -0.059372\n",
       "50%   -0.253708 -1.084731 -0.830551  0.615413\n",
       "75%    0.231783  0.637862 -0.188042  0.707897\n",
       "max    0.873966  1.508365  1.696941  1.246273"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d8614d3b-cbb0-4c62-9a6f-6aa0f7bc639e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23178298, -1.08473103, -0.60871159,  1.24627313],\n",
       "       [-0.8051254 , -2.0424981 , -0.83055101,  0.66059511],\n",
       "       [-1.36452889, -1.88299244,  1.69694146,  0.61541252],\n",
       "       [ 0.87396604,  1.50836467, -1.28259513,  0.70789746],\n",
       "       [-0.25370836,  0.63786164, -0.18804213, -0.05937169],\n",
       "       [ 0.16673377,  0.41769525, -1.10731038, -0.19481751]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warning - this breaks the driver due to memory - just like collect()\n",
    "# be careful\n",
    "psdf2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f2a2d82e-ed61-47b9-9bc3-26bfc5d669ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.231783</td>\n",
       "      <td>-0.805125</td>\n",
       "      <td>-1.364529</td>\n",
       "      <td>0.873966</td>\n",
       "      <td>-0.253708</td>\n",
       "      <td>0.166734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-1.084731</td>\n",
       "      <td>-2.042498</td>\n",
       "      <td>-1.882992</td>\n",
       "      <td>1.508365</td>\n",
       "      <td>0.637862</td>\n",
       "      <td>0.417695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>-0.608712</td>\n",
       "      <td>-0.830551</td>\n",
       "      <td>1.696941</td>\n",
       "      <td>-1.282595</td>\n",
       "      <td>-0.188042</td>\n",
       "      <td>-1.107310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>1.246273</td>\n",
       "      <td>0.660595</td>\n",
       "      <td>0.615413</td>\n",
       "      <td>0.707897</td>\n",
       "      <td>-0.059372</td>\n",
       "      <td>-0.194818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "A  0.231783 -0.805125 -1.364529  0.873966 -0.253708  0.166734\n",
       "B -1.084731 -2.042498 -1.882992  1.508365  0.637862  0.417695\n",
       "C -0.608712 -0.830551  1.696941 -1.282595 -0.188042 -1.107310\n",
       "D  1.246273  0.660595  0.615413  0.707897 -0.059372 -0.194818"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose\n",
    "psdf2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7ff44ab7-bbe1-47d6-851c-785c410ec46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.166734</td>\n",
       "      <td>0.417695</td>\n",
       "      <td>-1.107310</td>\n",
       "      <td>-0.194818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.253708</td>\n",
       "      <td>0.637862</td>\n",
       "      <td>-0.188042</td>\n",
       "      <td>-0.059372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.873966</td>\n",
       "      <td>1.508365</td>\n",
       "      <td>-1.282595</td>\n",
       "      <td>0.707897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.364529</td>\n",
       "      <td>-1.882992</td>\n",
       "      <td>1.696941</td>\n",
       "      <td>0.615413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.805125</td>\n",
       "      <td>-2.042498</td>\n",
       "      <td>-0.830551</td>\n",
       "      <td>0.660595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.231783</td>\n",
       "      <td>-1.084731</td>\n",
       "      <td>-0.608712</td>\n",
       "      <td>1.246273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "5  0.166734  0.417695 -1.107310 -0.194818\n",
       "4 -0.253708  0.637862 -0.188042 -0.059372\n",
       "3  0.873966  1.508365 -1.282595  0.707897\n",
       "2 -1.364529 -1.882992  1.696941  0.615413\n",
       "1 -0.805125 -2.042498 -0.830551  0.660595\n",
       "0  0.231783 -1.084731 -0.608712  1.246273"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort index\n",
    "psdf2.sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "24421bcc-fc85-45e7-a815-8240ffe9549f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.805125</td>\n",
       "      <td>-2.042498</td>\n",
       "      <td>-0.830551</td>\n",
       "      <td>0.660595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.364529</td>\n",
       "      <td>-1.882992</td>\n",
       "      <td>1.696941</td>\n",
       "      <td>0.615413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.231783</td>\n",
       "      <td>-1.084731</td>\n",
       "      <td>-0.608712</td>\n",
       "      <td>1.246273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.166734</td>\n",
       "      <td>0.417695</td>\n",
       "      <td>-1.107310</td>\n",
       "      <td>-0.194818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.253708</td>\n",
       "      <td>0.637862</td>\n",
       "      <td>-0.188042</td>\n",
       "      <td>-0.059372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.873966</td>\n",
       "      <td>1.508365</td>\n",
       "      <td>-1.282595</td>\n",
       "      <td>0.707897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "1 -0.805125 -2.042498 -0.830551  0.660595\n",
       "2 -1.364529 -1.882992  1.696941  0.615413\n",
       "0  0.231783 -1.084731 -0.608712  1.246273\n",
       "5  0.166734  0.417695 -1.107310 -0.194818\n",
       "4 -0.253708  0.637862 -0.188042 -0.059372\n",
       "3  0.873966  1.508365 -1.282595  0.707897"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort values\n",
    "psdf2.sort_values(by='B', ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c44fe2-a0f9-4689-b6d3-cb8de4fff888",
   "metadata": {},
   "source": [
    "# Missing Data - Pandas on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8ec03db1-6e6f-4be8-9edf-0070d6003588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you'll notice we are repeating a lot of the tasks \n",
    "# from 10 minutes to pandas \n",
    "pdf2 = pdf1.reindex(index=dates1[0:4], columns=list(pdf1.columns) + ['E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "589e3352-2c85-4ae1-8d56-6feb75edcd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf2.loc[dates1[0]:dates1[1], 'E'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "43b228f0-e92b-4850-a179-ac448fb8cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated for pandas 2.x+\n",
    "# explicitly cast dates to string\n",
    "pdf2.index = pdf2.index.astype(\"string\")\n",
    "psdf3 = ps.from_pandas(pdf2)\n",
    "# convert index back to datetime64\n",
    "psdf3.index = psdf3.index.astype(\"datetime64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3429fe43-77a7-407c-85f0-1b418d26d64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             A   B   C   D    E\n",
       "2022-01-01 NaN NaN NaN NaN  1.0\n",
       "2022-01-02 NaN NaN NaN NaN  1.0\n",
       "2022-01-03 NaN NaN NaN NaN  NaN\n",
       "2022-01-04 NaN NaN NaN NaN  NaN"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ef2fa301-49c1-4d09-ad8c-affd32a61c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [A, B, C, D, E]\n",
       "Index: []"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf3.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6452aba8-c98e-447b-bae4-78ce734da322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A    B    C    D    E\n",
       "2022-01-01  5.0  5.0  5.0  5.0  1.0\n",
       "2022-01-02  5.0  5.0  5.0  5.0  1.0\n",
       "2022-01-03  5.0  5.0  5.0  5.0  5.0\n",
       "2022-01-04  5.0  5.0  5.0  5.0  5.0"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf3.fillna(value=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9b0d8f-527e-4dfe-9c22-19530bc145e9",
   "metadata": {},
   "source": [
    "# Operations - Pandas on Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6b507-a0cb-41c5-b046-7a36cd3f12f9",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b915984d-a0c2-4464-8b08-3e82a082148a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A   -0.220619\n",
       "B    0.240984\n",
       "C    0.348187\n",
       "D   -0.862659\n",
       "dtype: float64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb20ff2-42a4-4c7f-8ecd-18c9fceac842",
   "metadata": {},
   "source": [
    "## Spark Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "347cf57d-e6eb-4b26-883d-9049eb9e6dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the current config value\n",
    "previous = spark.conf.get('spark.sql.execution.arrow.pyspark.enabled')\n",
    "previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7146679e-e0e4-4684-aae8-692f230f6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use default index prevent overhead.\n",
    "ps.set_option('compute.default_index_type', 'distributed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1ee8d4ab-b220-4d70-bce5-a1bb1c9c4910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings coming from Arrow optimizations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216906a-96da-4fc8-a83b-b70d14e1ec55",
   "metadata": {},
   "source": [
    "Let's toggle ```spark.sql.execution.arrow.pyspark.enabled``` to see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9612acea-78d0-4eb6-8422-0c2babca0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is supposed to be faster by an order of magnitude\n",
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f256c0f7-1a31-4fea-a870-4d8e8d661e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.29 s  762 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ps.range(3000000).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e395df2b-a90c-44d2-8719-b31905891e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is supposed to be slower\n",
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bce5b7-7596-44fa-bfb7-45ab35ac63f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit ps.range(3000000).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f263b6e-8197-4a45-adda-0b715ad8f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything back as it was\n",
    "ps.reset_option('compute.default_index_type')\n",
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', previous)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c33947-af1f-4b21-9a7e-216e183b89b5",
   "metadata": {},
   "source": [
    "# Grouping  \n",
    "  \n",
    "  \n",
    "It's the same split-apply-combine deal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b2936f-f187-422f-905d-a91de2f2b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf4 = ps.DataFrame({'A': ['foo', 'bar', 'foo', 'bar',\n",
    "                          'foo', 'bar', 'foo', 'foo'],\n",
    "                    'B': ['one', 'one', 'two', 'three',\n",
    "                          'two', 'two', 'one', 'three'],\n",
    "                    'C': np.random.randn(8),\n",
    "                    'D': np.random.randn(8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36143034-9676-4c05-9783-a47aeff13621",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da96c5-5e44-4f75-ad0f-dd6af42b27c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf4.groupby('A').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0897d230-59bb-466d-881d-95d010ba7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf4.groupby(['A', 'B']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46f6d8-b844-4eb4-acf8-b5d8df5ff6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pser = pd.Series(np.random.randn(1000),\n",
    "                 index=pd.date_range('1/1/2000', periods=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98dbf50-4f76-4543-903c-abc5e430de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "psser = ps.Series(pser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4bb833-7560-4d22-96b0-a620bef82e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "psser = psser.cummax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4177316-770e-48fc-a5c5-541bac983080",
   "metadata": {},
   "outputs": [],
   "source": [
    "psser.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b146fa9-b56c-437a-9c8e-06065022af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4 = pd.DataFrame(np.random.randn(1000, 4), index=pser.index,\n",
    "                   columns=['A', 'B', 'C', 'D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45332cad-eecf-4e6d-b191-87daef2696ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf5 = ps.from_pandas(pdf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787939c-912c-4169-894c-1a6417f5aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf5 = psdf5.cummax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92f20f-bad4-45bc-9bb1-4458c114c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf5.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795f3c1-66da-4753-b91b-82d793ea926e",
   "metadata": {},
   "source": [
    "# Getting data in/out - Pandas on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d86fa-7907-40b6-981f-574422e3bc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf4.to_csv('./data/foo.csv')\n",
    "ps.read_csv('./data/foo.csv').head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a9f5e-0c8f-40ce-bf6c-b6b0a576c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf4.to_parquet('./data/bar.parquet')\n",
    "ps.read_parquet('./data/bar.parquet').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e871f9-293f-4a90-84c5-bb934bc1e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f12fd2-370a-41a0-b98c-c70a9298a007",
   "metadata": {},
   "source": [
    "# Up Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bb84fc-f294-42f8-b08e-80ff2ce2503f",
   "metadata": {},
   "source": [
    "Check out the exercises on real-world datasets next"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
